{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitanaconda3condab801cdb560ae4e5299ccbfd790aaed0d",
   "display_name": "Python 3.7.3 64-bit ('anaconda3': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webscraping 101 \n",
    "this will act as my dojo for practicing webscaping\n",
    "\n",
    "The website we will be practicing on is called _books.toscrape.com_\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs4\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Empty lists to store the data we're scraping\n",
    "pages = []\n",
    "prices = []\n",
    "stars = []\n",
    "titles = []\n",
    "urls = []\n",
    "\n",
    "pages_scraped = 1\n",
    "\n",
    "#This block of code simply increments the page\n",
    "for i in range(1, pages_scraped + 1):\n",
    "    url = ('http://books.toscrape.com/catalogue/page-{}.html').format(i)\n",
    "    pages.append(url)\n",
    "\n",
    "#This collects all the source code per page\n",
    "for item in pages:\n",
    "    page = requests.get(item)\n",
    "    soup = bs4(page.text, 'html.parser')\n",
    "    # print(soup.prettify())\n",
    "\n",
    "    #Collects all the titles in the <h3>\n",
    "    for i in soup.findAll('h3'):\n",
    "        ttl = i.getText()\n",
    "        titles.append(ttl)\n",
    "\n",
    "    #Collects all the pricing for the books \n",
    "    for j in soup.findAll('p', class_= 'price_color'):\n",
    "        price = j.getText()\n",
    "        prices.append(price)\n",
    "\n",
    "    #Collects the star rating \n",
    "    for s in soup.findAll('p', class_='star-rating'):\n",
    "        for k,v in s.attrs.items():\n",
    "            star = v[1]\n",
    "            stars.append(star)\n",
    "    divs = soup.find_all('div', class_='image_container')\n",
    "    \n",
    "    # Collects the URLs for the images\n",
    "    for thumbs in divs:\n",
    "        tgs = thumbs.find('img', class_='thumbnail')\n",
    "        urlss = 'https://books.toscrape.com/' + str(tgs['src'])     \n",
    "        new_urls = urlss.replace('../','')\n",
    "        urls.append(new_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Title': titles, 'Prices': prices, 'Stars': stars, 'URLs': urls}"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pandas DataFrame\n",
    "The cell above will create a nicely formatted dataframe that will show the information laid out using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data)\n",
    "df.index +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exporting the data into an Excel format\n",
    "Once again we will use pandas to show the data but this time as an excel sheet\n",
    "path to the file is: /home/user/books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('/home/user/books.xlsx')\n",
    "df.to_csv('/home/user/books.csv')"
   ]
  }
 ]
}